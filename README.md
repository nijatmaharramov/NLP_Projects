# NLP_Projects
# 🇬🇧→🇪🇸 Transformer-Based English to Spanish Translator

This project implements a custom **Transformer-based Neural Machine Translation (NMT)** system to translate English sentences into Spanish.

Built entirely using TensorFlow and Keras, the model mimics the "Attention Is All You Need" architecture with custom embeddings, multi-head attention, masked decoding, and greedy inference.

---

## 🔧 Features

- ✅ Custom Transformer encoder-decoder
- ✅ Positional encoding with learnable embeddings
- ✅ Multi-head self-attention & cross-attention
- ✅ Causal mask for autoregressive decoding
- ✅ Tokenization with `TextVectorization` layers
- ✅ Greedy decoding at inference time

---

## 📁 Project Structure
The project is currently contained within a single Colab notebook, which includes all the necessary steps for building and training the English-to-Spanish translation model. The notebook is organized as follows:
├── translator_en_es.ipynb 
└── README.md # Project documentation


